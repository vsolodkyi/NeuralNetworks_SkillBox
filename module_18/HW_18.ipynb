{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Применение TensorRT для оптимизации нейросетей. Практика.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsolodkyi/NeuralNetworks_SkillBox/blob/main/module_18/HW_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgshItiNbYmH"
      },
      "source": [
        "# Применение TensorRT для оптимизации нейросетей\n",
        "\n",
        "В этом уроке мы рассмотрим на практике оптимизацию и инференс нейронной сети с помощью библотеки TensorRT.\n",
        "\n",
        "Изначально TensorRT существовала в виде отдельной бибилотеки, но относительно недавно её функционал был в том числе интегрирован в TensorFlow. Именно этим мы и воспользуемся в этом уроке. При такой интеграции на выходе мы всё еще получаем TensorFlow модель, просто часть её графа будут оптимизированы и вычислены (во время инференса) с помощью TensorRT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yeG_jLT-b2h"
      },
      "source": [
        "### Используем TensorFlow 2.0\n",
        "\n",
        "На момент подготовки этих материалов в Google Colab по умолчанию используется версия TensorFlow 1.X\n",
        "\n",
        "Переключаемся на версию 2.0 (работает только в Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mpXpfED-Z7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fcd182e-89a6-4a95-86a0-4bce553e5fcc"
      },
      "source": [
        "!pip install tensorflow==2.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.6\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.6.0%2Bzzzcolab20220506153740-cp37-cp37m-linux_x86_64.whl (564.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 564.4 MB 2.7 kB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (3.3.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (3.17.3)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.15.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (2.8.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (0.37.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.1.0)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.47.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.6) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.6) (3.2.0)\n",
            "Building wheels for collected packages: clang, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=b55e05cd35d088d3e05d2ff3810307a2cfb9ad83e0ce40263ad9b8f4fffca4ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68713 sha256=d7ca742699320a8df19971dbe9abe61807206edf3ecdcef13ffb3e56c94c4b41\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built clang wrapt\n",
            "Installing collected packages: typing-extensions, numpy, absl-py, wrapt, gast, flatbuffers, clang, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 clang-5.0 flatbuffers-1.12 gast-0.4.0 numpy-1.19.5 tensorflow-2.6.0+zzzcolab20220506153740 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.6.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ao4zqv7554K",
        "outputId": "18437cbc-d9e0-472a-bbd0-03437ba4e017"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.6.*\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 15.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1c9g1MHeUCl"
      },
      "source": [
        "### Загрузка библиотек"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9ZhQFL9d7LaF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPJ0YaW58SXY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e354DpM-riUG",
        "outputId": "1cb8019c-8f90-412d-8668-c9456ead792e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1ug-YTn1tFWA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1DhfdwVUYlr"
      },
      "source": [
        "### Импорт TensorRT\n",
        " Будем использовать TensorRT, котрый идёт внутри TensorFlow.\n",
        "\n",
        " В реальной среде может потребоваться произвести дополнительную установку недостающих компонентов TensorRT, но в Google Colab уже установлено всё, что нужно.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgvRbJrJsxHs"
      },
      "source": [
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMn7JDZUk9l"
      },
      "source": [
        "### Создание модели \n",
        "\n",
        "Создадим свёрточную нейронную сеть с большим количеством свёрточных слоёв.\n",
        "\n",
        "Кроме того, для TensorRT оптимизации необходимо фиксировать размер входа. Делаем это с помощью метода `_set_inputs()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KJfXErosxF7"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "     tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2, 2)),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2, 2)),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2, 2)),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model._set_inputs(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLuDFOgBUpHj"
      },
      "source": [
        "### Сохранение модели \n",
        "\n",
        "Сохраним модель в виде `saved_model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAGeUP93sxCO"
      },
      "source": [
        "model.save('saved_model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6run0z2UrgO"
      },
      "source": [
        "### Оптимизация модели с помощью TensorFlow\n",
        "\n",
        "А теперь давайте произведем оптимизацию нашей модели с помощью TensorRT.\n",
        "\n",
        "Сначала создадим TensorRT конвертер (`converter`) и укажем ему путь до нашей сохранённой неоптимизированной TensorFlow модели. Если нужно как-то еще сконфигурировать процесс оптимизации, можно передать дополнительные параметры в конструктор `TrtGraphConverterV2`, но мы будем использовать параметры по умолчанию.\n",
        "\n",
        "После этого просто вызываем метод `convert()` и TensorRT применит все свои стратегии для оптимизации нашей модели. Важно запускать этот ноутбук в режиме GPU, так как TensorRT работает только с GPU.\n",
        "\n",
        "После оптимизации можно сохранить новую модель в стандартном формате `saved_model`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IefTmdcqsxAN"
      },
      "source": [
        "converter = trt.TrtGraphConverterV2(input_saved_model_dir='saved_model')\n",
        "converter.convert()\n",
        "converter.save('saved_model_trt')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvVLetldUwBD"
      },
      "source": [
        "### Загрузка оптимизированной TensorRT модели\n",
        "\n",
        "Теперь можно загрузить оптимизированную модель и произвести инференс. Во время инференса такой модели TensorFlow будет обращаться к инференс движку TensorRT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhTS4MvUsw-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd2bff3-b618-4b60-f918-6623079aa034"
      },
      "source": [
        "model_trt = tf.keras.models.load_model('saved_model_trt')\n",
        "\n",
        "# Warm-up\n",
        "_=model_trt(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8HybVM0UDHj"
      },
      "source": [
        "### Сравнение скорости работы двух моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKgvp222UHev"
      },
      "source": [
        "Запустим инференс для обеих моделей со случайным входом и узнаем среднюю скорость работы каждой из моделей с помощью магической команды `%%timeit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqP7bYrrtO_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1202bb3-026b-4adc-ea7d-6720fdbccb8a"
      },
      "source": [
        "%%timeit -n 10 -r 10\n",
        "\n",
        "q = model(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.8 ms ± 2.16 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv97jcIjtPBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0499ae-7aac-424e-d05f-8f246b9dac1d"
      },
      "source": [
        "%%timeit -n 10 -r 10\n",
        "\n",
        "q = model_trt(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.21 ms ± 374 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdcUkufULqX"
      },
      "source": [
        "TensorRT модель получилась быстрее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcyTQv6euJnx"
      },
      "source": [
        "**[Задание 1]** Сравните скорость работы двух моделей при различных гиперпараметрах (размер батча, размер входа, количество слоёв). Рассчитайте коэффициент ускорения (во сколько раз одна модель быстрее другой) для каждой конфигурации. Постройте соответствующие графики. (Например, график зависимости ускорения от размера входа при условии, что всё остальное фиксировано). Для этого задания вам понадобится самостоятельно реализовать способ измерения среднего времени инференса модели."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10 -r 10\n",
        "\n",
        "q = model(np.zeros((128, 28, 28, 1), dtype=np.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvIKpV3ftrWX",
        "outputId": "4508bfb8-2c00-41d2-c0a4-e6fdce40d1a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "14.6 ms ± 10.1 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10 -r 10\n",
        "\n",
        "q = model_trt(np.zeros((128, 28, 28, 1), dtype=np.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UxDm6rUtv_O",
        "outputId": "33405176-9e02-4c62-b4d2-3e39caa39aab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 6.45 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "7.95 ms ± 8.17 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OazFRuv-744o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **HOMEWORK model optimization TensorRT**"
      ],
      "metadata": {
        "id": "vm7L2bCO76c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "oaK_0dtH8GB4",
        "outputId": "fcb90edd-de34-41b8-cdb5-f693e917fcf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/MyDrive/Skillbox/model_1/best_checkpoint.hdf5"
      ],
      "metadata": {
        "id": "pKe7ZY-08386",
        "outputId": "08e94839-2d2b-4326-a515-1265194b6f14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_checkpoint.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_model = tf.keras.models.load_model('gdrive/MyDrive/Skillbox/model_1/best_checkpoint.hdf5')\n",
        "\n",
        "# Check its architecture\n",
        "tf_model.summary()"
      ],
      "metadata": {
        "id": "kdaOYXtV9mEK",
        "outputId": "1713d749-082f-413e-808e-697587935b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_model.save('gdrive/MyDrive/Skillbox/model_1/smodel')"
      ],
      "metadata": {
        "id": "F1napzoy_ggz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10 -r 10\n",
        "q = tf_model(np.zeros((128,784), dtype=np.float32))"
      ],
      "metadata": {
        "id": "Gw3BnhHX9ypY",
        "outputId": "7c931c8d-f9f3-47b5-c697-ad6b06351d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.59 ms ± 152 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter_new = trt.TrtGraphConverterV2(input_saved_model_dir='gdrive/MyDrive/Skillbox/model_1/smodel')\n",
        "converter_new.convert()\n",
        "converter_new.save('gdrive/MyDrive/Skillbox/model_1/saved_model_trt_new')"
      ],
      "metadata": {
        "id": "z2drALY7-6pr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trt_model = tf.keras.models.load_model('gdrive/MyDrive/Skillbox/model_1/saved_model_trt_new')\n",
        "\n",
        "# Warm-up\n",
        "#_=trt_model(np.zeros((1, 28, 28, 1), dtype=np.float32))"
      ],
      "metadata": {
        "id": "j_cR46fq_0GZ",
        "outputId": "dc8f5394-e6e4-4fd4-d97c-abdaa678bc45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10 -r 10\n",
        "q = tf_model(np.zeros((10,784), dtype=np.float32))"
      ],
      "metadata": {
        "id": "CpuiVftX_tba",
        "outputId": "44859929-90a1-4412-e55f-7e8d272703dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.36 ms ± 254 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10 -r 10\n",
        "q = trt_model(np.zeros((10,784), dtype=np.float32))"
      ],
      "metadata": {
        "id": "NexMaVRD_vBQ",
        "outputId": "48018c18-603a-458a-aa79-d4fe95e81cc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 5.45 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1.26 ms ± 957 µs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
          ]
        }
      ]
    }
  ]
}