{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14 homework text classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMR4nvm/sKBpGMFZlJktJ4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsolodkyi/NeuralNetworks_SkillBox/blob/main/module_14/14_homework_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1ch-8TTNpF9",
        "outputId": "ac1a8b4a-e445-4781-e2f3-25d35c26d50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset - https://drive.google.com/file/d/1CVRGIvWpymsqopO-22VD1CkatAE5OLJH/view?usp=sharing"
      ],
      "metadata": {
        "id": "kvdMgHoZB7XW"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_all = pd.read_csv('train_data.txt', sep=':::', header=None, names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])\n",
        "test = pd.read_csv('test_data.txt', sep=':::', header=None, names=['ID', 'TITLE', 'DESCRIPTION'])\n",
        "test_solution = pd.read_csv('test_data_solution.txt', sep=':::', header=None, names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])\n",
        "print(train_all.shape)\n",
        "print(test.shape)\n",
        "print(test_solution.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZDbRmmbN2OZ",
        "outputId": "2b4bf904-c71b-400a-be7e-3e141a467266"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54214, 4)\n",
            "(54200, 3)\n",
            "(54200, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_all.GENRE.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgXWLAVJPtai",
        "outputId": "fd2050ee-a7c7-4665-d618-31a7ade92899"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' drama ', ' thriller ', ' adult ', ' documentary ', ' comedy ',\n",
              "       ' crime ', ' reality-tv ', ' horror ', ' sport ', ' animation ',\n",
              "       ' action ', ' fantasy ', ' short ', ' sci-fi ', ' music ',\n",
              "       ' adventure ', ' talk-show ', ' western ', ' family ', ' mystery ',\n",
              "       ' history ', ' news ', ' biography ', ' romance ', ' game-show ',\n",
              "       ' musical ', ' war '], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rHB8UQ5oSQh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Pre-processing**"
      ],
      "metadata": {
        "id": "RIQQ6qsUSXUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_all.DESCRIPTION[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "u90tQ1B_Scn4",
        "outputId": "d09f3bf6-e6e1-4c13-80d8-74d850a1ef32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Listening in to a conversation between his doctor and parents, 10-year-old Oscar learns what nobody has the courage to tell him. He only has a few weeks to live. Furious, he refuses to speak to anyone except straight-talking Rose, the lady in pink he meets on the hospital stairs. As Christmas approaches, Rose uses her fantastical experiences as a professional wrestler, her imagination, wit and charm to allow Oscar to live life and love to the full, in the company of his friends Pop Corn, Einstein, Bacon and childhood sweetheart Peggy Blue.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our text preprocessing will include the following steps:**\n",
        "\n",
        "Convert all text to lower case.\n",
        "\n",
        "Replace REPLACE_BY_SPACE_RE symbols by space in text.\n",
        "\n",
        "Remove symbols that are in BAD_SYMBOLS_RE from text.\n",
        "\n",
        "Remove “x” in text.\n",
        "\n",
        "Remove stop words.\n",
        "\n",
        "Remove digits in text."
      ],
      "metadata": {
        "id": "lq9iC0S0Sx7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "import string\n",
        "\n",
        "# дополнительный словарь со знаками пунктуации\n",
        "nltk.download('punkt', download_dir='.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmRBQYSATp3q",
        "outputId": "6caef2da-bae9-4012-c3e4-22b91115a3d4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to ....\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_all = train_all.reset_index(drop=True)\n",
        "#REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]-')\n",
        "#BAD_SYMBOLS_RE = re.compile('[^0-9#a-z# +_]')\n"
      ],
      "metadata": {
        "id": "A20LI5gtStd7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\n",
        "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
        "    'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
        "    'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
        "    'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
        "    'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
        "    'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
        "    'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out',\n",
        "    'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
        "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
        "    'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'shold',\n",
        "    \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
        "    'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
        "    'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
        "    'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"\n",
        "]"
      ],
      "metadata": {
        "id": "WBp-SRXyWQJG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(raw_text: str):\n",
        "    \"\"\"Функция для токенизации текста\n",
        "    \n",
        "    :param raw_text: исходная текстовая строка\n",
        "    \"\"\"\n",
        "    #raw_text = REPLACE_BY_SPACE_RE.sub(' ', raw_text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    #raw_text = BAD_SYMBOLS_RE.sub('', raw_text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "   \n",
        "    tokenized_str = nltk.word_tokenize(raw_text)\n",
        "    tokens = [i.lower() for i in tokenized_str if ( i not in string.punctuation )]\n",
        "    filtered_tokens = [i for i in tokens if ( i not in stop_words )]\n",
        "\n",
        "    return filtered_tokens\n",
        "\n"
      ],
      "metadata": {
        "id": "hEL0dum4WVvn"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# применяем функцию в датафрейму с помощью метода .apply()\n",
        "tokenized_desc = train_all['DESCRIPTION'].apply(tokenize_text)\n",
        "\n",
        "# добавляем новую колонку в исходный датафрейм\n",
        "train_all = train_all.assign(\n",
        "    descr_new=tokenized_desc\n",
        ")\n",
        "\n",
        "train_all.descr_new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGc-ScCsWb9P",
        "outputId": "4431f80f-5dfd-4bb7-c0f6-5fc76f646239"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [listening, conversation, doctor, parents, 10-...\n",
              "1    [brother, sister, past, incestuous, relationsh...\n",
              "2    [bus, empties, students, field, trip, museum, ...\n",
              "3    [help, unemployed, father, make, ends, meet, e...\n",
              "4    [film, 's, title, refers, un-recovered, bodies...\n",
              "Name: descr_new, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_all.DESCRIPTION[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "vx9S6_HEYMSg",
        "outputId": "baa3044f-f89c-477c-b1d2-b0f4f5a476ff"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Listening in to a conversation between his doctor and parents, 10-year-old Oscar learns what nobody has the courage to tell him. He only has a few weeks to live. Furious, he refuses to speak to anyone except straight-talking Rose, the lady in pink he meets on the hospital stairs. As Christmas approaches, Rose uses her fantastical experiences as a professional wrestler, her imagination, wit and charm to allow Oscar to live life and love to the full, in the company of his friends Pop Corn, Einstein, Bacon and childhood sweetheart Peggy Blue.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "x5-0FXmtbcmY"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 20000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(train_all['descr_new'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgTU_JXwaw0B",
        "outputId": "1d237d70-afd2-4cfc-c5de-5360f0b8c72d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 147789 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenizer.texts_to_sequences(train_all['descr_new'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HieF01Iqbw-V",
        "outputId": "10f8e0fd-2995-41e8-e240-9bd92d75993a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (54214, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(train_all['GENRE']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL66amDvcQmv",
        "outputId": "231b3afb-58bf-4eac-dc19-12acb78f7234"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (54214, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-UQiQM9catt",
        "outputId": "12040ac5-a8b2-4d3b-f96a-953688162322"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43371, 256) (43371, 27)\n",
            "(10843, 256) (10843, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "#model.add(tf.keras.layers.SpatialDropout1D(0.2))\n",
        "model.add(tf.keras.layers.LSTM(50, return_sequences=True,  dropout=0.25, recurrent_dropout=0.4))\n",
        "model.add(tf.keras.layers.LSTM(16, return_sequences=False,  dropout=0.25, recurrent_dropout=0.5))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(Y_train.shape[1], activation='softmax'))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=5e-3)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsoWUnsiclaP",
        "outputId": "a0d60877-302e-43cc-d0ac-523aa8abb397"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 256, 100)          2000000   \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 256, 50)           30200     \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 16)                4288      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               4352      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 27)                6939      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,045,779\n",
            "Trainable params: 2,045,779\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 256\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    verbose=1\n",
        "                    , epochs=epochs, batch_size=batch_size,validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztMa4RLsdp_o",
        "outputId": "3badd818-944b-4368-beeb-5555e164d21b"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "119/119 [==============================] - 241s 2s/step - loss: 2.3859 - accuracy: 0.2606 - val_loss: 2.1770 - val_accuracy: 0.4057\n",
            "Epoch 2/5\n",
            "119/119 [==============================] - 231s 2s/step - loss: 1.9248 - accuracy: 0.4401 - val_loss: 1.8400 - val_accuracy: 0.4576\n",
            "Epoch 3/5\n",
            "119/119 [==============================] - 232s 2s/step - loss: 1.6178 - accuracy: 0.5139 - val_loss: 1.8266 - val_accuracy: 0.4706\n",
            "Epoch 4/5\n",
            "119/119 [==============================] - 231s 2s/step - loss: 1.3760 - accuracy: 0.5901 - val_loss: 1.8564 - val_accuracy: 0.4838\n",
            "Epoch 5/5\n",
            "119/119 [==============================] - 232s 2s/step - loss: 1.1254 - accuracy: 0.6681 - val_loss: 2.0445 - val_accuracy: 0.4849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_all.GENRE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHFV3T9nnfK2",
        "outputId": "41260859-6f12-450a-c56e-d91c4896ba66"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               drama \n",
              "1            thriller \n",
              "2               adult \n",
              "3               drama \n",
              "4               drama \n",
              "             ...      \n",
              "54209          comedy \n",
              "54210          horror \n",
              "54211     documentary \n",
              "54212          comedy \n",
              "54213         history \n",
              "Name: GENRE, Length: 54214, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(train_all['GENRE']).columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYIuDGctolHL",
        "outputId": "289747cf-7042-41cd-a158-68c5bf223442"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' action ', ' adult ', ' adventure ', ' animation ', ' biography ',\n",
              "       ' comedy ', ' crime ', ' documentary ', ' drama ', ' family ',\n",
              "       ' fantasy ', ' game-show ', ' history ', ' horror ', ' music ',\n",
              "       ' musical ', ' mystery ', ' news ', ' reality-tv ', ' romance ',\n",
              "       ' sci-fi ', ' short ', ' sport ', ' talk-show ', ' thriller ', ' war ',\n",
              "       ' western '],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.get_dummies(test_solution['GENRE']).columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS2FwnYRpYJj",
        "outputId": "228f112f-4cfb-4179-caac-d00a971a6228"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([' action ', ' adult ', ' adventure ', ' animation ', ' biography ',\n",
              "       ' comedy ', ' crime ', ' documentary ', ' drama ', ' family ',\n",
              "       ' fantasy ', ' game-show ', ' history ', ' horror ', ' music ',\n",
              "       ' musical ', ' mystery ', ' news ', ' reality-tv ', ' romance ',\n",
              "       ' sci-fi ', ' short ', ' sport ', ' talk-show ', ' thriller ', ' war ',\n",
              "       ' western '],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get dummies is the same for train and test datasets. we can use same get_dummies function"
      ],
      "metadata": {
        "id": "03WqEwM5pgNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply token function into test solution dataframe with method .apply()\n",
        "test_tokenized_desc = test_solution['DESCRIPTION'].apply(tokenize_text)\n",
        "\n",
        "# добавляем новую колонку в исходный датафрейм\n",
        "test_solution = test_solution.assign(\n",
        "    descr_new=test_tokenized_desc\n",
        ")\n",
        "\n",
        "test_solution.descr_new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFkSHHqJprjK",
        "outputId": "1aa76206-3d2b-4f3d-9f45-7a6dd3139127"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [l.r, brane, loves, life, car, apartment, job,...\n",
              "1    [spain, march, 1964, quico, naughty, child, th...\n",
              "2    [one, year, life, albin, family, shepherds, no...\n",
              "3    [father, died, n't, spoken, brother, 10, years...\n",
              "4    [known, internationally, martial, arts, supers...\n",
              "Name: descr_new, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_x = tokenizer.texts_to_sequences(test_solution['descr_new'].values)\n",
        "test_x = pad_sequences(test_x, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', test_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4a43zH7qJd6",
        "outputId": "08a53fba-6272-474a-e4c9-9eb072bfa35d"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (54200, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicts = pd.get_dummies(train_all['GENRE']).columns\n",
        "def get_num_dummies(word):\n",
        "  #num = None\n",
        "  for i,k in enumerate(dicts):\n",
        "    if word == k:\n",
        "      return i\n",
        "  \n",
        "  #return [i for i,k in enumerate(dicts) if  str(k) == word]\n",
        "   \n",
        "get_num_dummies(' mystery ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJzB-j9AqUxc",
        "outputId": "7cac5116-ad5b-41bd-f1a6-7f95b811a893"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y = test_solution['GENRE'].apply(get_num_dummies)\n"
      ],
      "metadata": {
        "id": "D8Ez8qbssOGO"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_x)"
      ],
      "metadata": {
        "id": "F7mAnsfEvCri"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2fDd9TFvODz",
        "outputId": "ec6b8761-9793-4646-aa0e-b16bfd14fe81"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 8, 7, ..., 8, 5, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm-cWoyVv-WV",
        "outputId": "d3abf5c4-ff3a-4004-bd57-bcc663d3510f"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        24\n",
              "1         5\n",
              "2         7\n",
              "3         8\n",
              "4         8\n",
              "         ..\n",
              "54195    13\n",
              "54196    26\n",
              "54197     1\n",
              "54198     8\n",
              "54199     8\n",
              "Name: GENRE, Length: 54200, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error, accuracy_score"
      ],
      "metadata": {
        "id": "_OrW5MwOwBxw"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score on test dataset is {:.4f}'.format(accuracy_score(test_y, pred.argmax(axis=1))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDkdZmsDwqhv",
        "outputId": "147a32bd-51ca-4751-f2b3-ba527e240813"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on test dataset is 0.4835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "SZ0QwKMOAQNQ"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  \n",
        "  k = random.randint(0, len(test_x))\n",
        "  print ('description text: {}'.format(test_solution['DESCRIPTION'][k]))\n",
        "  print('True genre is: {}'.format(test_solution['GENRE'][k]))\n",
        "  print('Predict genre is: {}'.format(dicts[pred[k].argmax()]))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJDoVEgkwnnB",
        "outputId": "e84a2e98-f0be-41c6-bddd-76c110eb834a"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "description text:  In 2006, Amanda and Casey Arrington moved from Texas to Durham, North Carolina, where they started a group called Coalition to Unchain Dogs. The purpose of the group, in the long term, was to advocate for the passage of legislation banning or restricting the practice of chaining. In the short term, the group would provide free fences, free spay/neuter, and free basic veterinary care for chained dogs in the community, so that the dogs could have room to run and be free from their chains. This short documentary follows the experience of the Coalition through two of the group's volunteers, Robert and Lori Hensley, as they and the Arringtons rescue Fluffy, a dog severely injured by an embedded tether. Fluffy's story serves as a frame for the Coalition's work and an illustration of the challenges the group has to overcome. The film documents Amanda's skills at building trust with Durham's community members, the deliberations and questions the Arringtons and Hensleys wrestle with during their rescue of Fluffy, and the successful community organizing efforts of the Coalition that culminate in the passage of an ordinance banning the chaining of dogs in Durham.\n",
            "True genre is:  short \n",
            "Predict genre is:  documentary \n",
            "\n",
            "description text:  As a small child Christopher sat with his siblings upstairs in their Rock ferry home as a family friend was murdered in the hallway below. As the victim breathed his very last breath, little Christopher's life was turned upside down and inside out. The Power family left to start a new life elsewhere in a plight to escape the shackles of trauma but it was exactly that move that launched Christopher into turmoil, torn between his intelligent conscience and the gritty reality of life on a council estate in the 1980's.Caught up in a life of petty crime and gambling, fuelled by relentless drinking and solvent abuse from a painfully young age, this once-pure child suffered harrowing consequences at the hands of corruption. Bound in a straight jacket at six years old with speech problems and extreme hyperactivity was just the start for Christopher. His childhood transpired to revolve around running riot with a local gang, falling foul of the law and eventually serving time at a young offender's institute, and later in a Remand Prison. It was during his time in prison that Christopher had a chance meeting with a stranger that would again, change his life forever...\n",
            "True genre is:  drama \n",
            "Predict genre is:  drama \n",
            "\n",
            "description text:  Yu-jin refuses to allow herself to become pregnant--much to her husband's disappointment. She is too busy with her career to even take care of the house, let alone a baby. But Yu-jin's thoughts that she is successful begin to crumble when she discovers her husband and the housekeeper she hired in bed together.\n",
            "True genre is:  drama \n",
            "Predict genre is:  comedy \n",
            "\n",
            "description text:  Gun violence is one of the most pressing social issues facing America today. ONE LIFE looks into this timely topic through the unique prism of an art installation dubbed The Embassy that takes place in New Orleans 8th Ward. The Embassy is a collaboration between artist Kirsha Kaechele & former NBA player Randy Livingston. The installation kicks off with a gun buyback & a Mardi Gras inspired street parade to mark the opening of a free recording studio where youth affected by gun violence come to record their songs with platinum selling recording artist Mr Serv-On. The story follows two aspiring recording artists, Mariah & KG, from their initial meetings with Mr Serv-On, to writing & recording their own songs, to performing at a neighborhood Block Party. The young artists' journeys are inter-cut with formal interviews with experts on the justice system, the prison system, education and mental health who give their take on why the rate of gun deaths in New Orleans is so high, & what can be done about it. For our young artists, it's a transformational journey leading to an emotional resolution for one of them & the possibility of stardom for the other. The film treats New Orleans as a culturally specific microcosm of the United States, and situates the story in the broader context of shooting deaths across the US. This is contrasted with the relative peacefulness of Tasmania, where the Embassy was conceived. The lively soundtrack combines rap music with a lyrical original score.\n",
            "True genre is:  documentary \n",
            "Predict genre is:  documentary \n",
            "\n",
            "description text:  Documentary which goes in search of real-life versions of the characters and situations featured in the comedy series _\"Little Britain\" (2003)_ (qv), exploring contemporary Britain for the 'only gay in the village', men that think they are ladies and outspoken teenagers.\n",
            "True genre is:  documentary \n",
            "Predict genre is:  documentary \n",
            "\n"
          ]
        }
      ]
    }
  ]
}